{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T20:58:02.262723Z",
     "iopub.status.busy": "2024-05-30T20:58:02.262310Z",
     "iopub.status.idle": "2024-05-30T20:58:02.267706Z",
     "shell.execute_reply": "2024-05-30T20:58:02.266845Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T20:58:02.271915Z",
     "iopub.status.busy": "2024-05-30T20:58:02.271673Z",
     "iopub.status.idle": "2024-05-30T20:58:02.985263Z",
     "shell.execute_reply": "2024-05-30T20:58:02.984450Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "from numpy import mean\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation For Exponential Distribution<br>\n",
    "In this example, given data $\\mathcal{D}$, we are going to estimate the parameters of an Exponential Distribution using<br>\n",
    "- Bayesian Parameter Estimation<br>\n",
    "- MAP<br>\n",
    "- Note that the equation for an exponential distribution is<br>\n",
    "$$ p(x) = \\lambda e^{-\\lambda x} $$<br>\n",
    "$$ E[X] = \\frac{1}{\\lambda}$$<br>\n",
    "- For Exponential distribution, the conjugate prior is the Gamma distribution where<br>\n",
    "$$ p(\\lambda) = \\frac{1}{\\Gamma(k) \\theta^k} \\lambda^{k-1} e^{-\\lambda/\\theta}.$$<br>\n",
    "### The likelihood function<br>\n",
    "Given n samples, the likelihood function is<br>\n",
    "$$ p(X = \\mathcal{D}|\\lambda) = \\prod_i \\; \\lambda e^{- \\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_i \\; x_i}$$.<br>\n",
    "Given the joint likelihood function and the conjugate prior, we know that $p(\\lambda|X=\\mathcal{D}) \\propto  p(X=\\mathcal{D}|\\lambda)p(\\lambda)$, therefore<br>\n",
    "$$p(\\lambda|X=\\mathcal{D}) \\propto \\left( \\lambda^n e^{-\\lambda \\sum_i \\; x_i} \\right) \\left( \\frac{1}{\\Gamma(k) \\theta^k} \\lambda^{k-1} e^{-\\lambda/\\theta} \\right).$$<br>\n",
    "If we combine the terms together, we get<br>\n",
    "$$p(\\lambda|X=\\mathcal{D}) \\propto \\frac{1}{\\Gamma(k) \\theta^k} \\lambda^{k+n-1} e^{-\\lambda (\\sum_i x_i - \\frac{1}{\\theta})}$$<br>\n",
    "Since $p(\\lambda|X=\\mathcal{D})$ is in terms of $\\lambda$, the term $\\frac{1}{\\Gamma(k) \\theta^k}$ at the front is just a constant, therefore<br>\n",
    "$$p(\\lambda|X=\\mathcal{D}) = \\eta \\lambda^{k+n-1} e^{-\\lambda (\\sum_i x_i - \\frac{1}{\\theta})}$$<br>\n",
    "- Pay special attention to the fact that we went from $\\propto$ to = sign. <br>\n",
    "- This is because we may not know the exact proportion of $\\eta$, but we the posterior is equal to a constant multiple<br>\n",
    "- Once we simplified the equation, we notice that the structure of the residual equation is identical to a gamma distribution if<br>\n",
    "$$\\hat{k} = k + n, \\quad \\quad \\hat{\\theta} = \\frac{1}{\\sum_i x_i - 1/\\theta}$$<br>\n",
    "Giving us the posterior distribution<br>\n",
    "$$ p(\\lambda|X=\\theta) = \\frac{1}{\\Gamma(\\hat{k}) \\; \\hat{\\theta}^\\hat{k}} \\; \\lambda^{\\hat{k}-1} e^{-\\lambda/\\hat{\\theta}}.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
