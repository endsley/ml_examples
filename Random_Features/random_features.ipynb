{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Chieh Wu, 9/13/2022<br>\n",
    "This function calculates the Gaussian Kernel by approximate it through Random fourier Feature and Orthogonal Random Feature technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Fourier Feature**<br>\n",
    "Given data $X \\in \\mathbb{R}^{n \\times d}$, RFF says that a kernel function is <br>\n",
    "$$k(x,y) = E_{p(\\omega)}[ cos(w^T x + \\theta) cos(w^T y + \\theta)] $$<br>\n",
    "and therefore can be approximated with<br>\n",
    "$$k(x,y) = \\frac{2}{m} \\sum_i^m cos(w_i^T x + \\theta) cos(w_i^T y + \\theta) $$<br>\n",
    "This implies that the feature map is <br>\n",
    "$$ \\phi(x) \\approx \\sqrt{\\frac{2}{m}} [cos(w_1^T x + \\theta), cos(w_2^T x + \\theta), ... , cos(w_m^T x + \\theta)]$$<br>\n",
    "Given $W \\in \\mathbb{R}^{d \\times m}$ the entire dataset $X$, then<br>\n",
    "$$ \\phi(X) \\approx \\sqrt{\\frac{2}{m}} cos[XW + \\theta]$$<br>\n",
    "The the element of the W matrix is a normal gaussian distribution divided by σ of the gaussian distribution<br>\n",
    "θ is randomly generated using uniform distribution between 0 to 2π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Structured Orthogonal Random Feature SORF**<br>\n",
    "The SORF replaces the $W$ matrix with<br>\n",
    "$$W = \\frac{\\sqrt{d}}{\\sigma} HD_1HD_2HD_3$$<br>\n",
    "$H$ is a normalized Hadamard matrix, the normalization is such that $I = H^TH$<br>\n",
    "Therefore $H$ is the Hadamard matrix divided by $\\frac{1}{\\sqrt{d}}$<br>\n",
    "and D is a diagonal matrix with the diagonal elements sampled from Rademacher Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since Hadamard matrix size is alway in the power of 2 $2^n$, the dimension of the data is probably not the same.<br>\n",
    "In these cases, pad the data with 0s as the extra dimensions. Also, the width of the SORF is always set to the dimension<br>\n",
    "of the data after padding. Therefore, to make the width even longer, we must generate multiple size d matrices and <br>\n",
    "concatenate them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import numpy.matlib\n",
    "from torch.autograd import Variable\n",
    "from numpy.random import rand\n",
    "import torch.nn.functional as F\n",
    "from scipy.linalg import hadamard\n",
    "from tools import *\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_feature:\n",
    "\t# sample_num, the larger the better approximation\n",
    "\t# random_feature_method can be 'orthogonal' (default) or 'rff'\n",
    "\tdef __init__(self, kernel='rbk', sigma=1, random_feature_method='orthogonal', sample_num=482):\n",
    "\t\tself.method = random_feature_method\n",
    "\t\tself.kernel = kernel\n",
    "\t\tself.m = sample_num\t\t# the number of samples used to approximate k(x,y)\n",
    "\t\tself.θ = None\t\t\t# phase shift\n",
    "\t\tself.σ = sigma\n",
    "#\n",
    "\tdef sample_rademacher_distribution(self, num_of_samples):\n",
    "\t\tr = np.random.binomial(1, 0.5, int(num_of_samples))\n",
    "\t\tr = 2*(r - 0.5)\n",
    "\t\tD = np.diag(r)\n",
    "\t\treturn D\n",
    "#\n",
    "\tdef initialize_random_features(self, X):\n",
    "\t\tif self.θ == None:\n",
    "\t\t\tX0 = X\n",
    "\t\t\tN = X.shape[0]\n",
    "\t\t\td = X.shape[1]\n",
    "\t\t\tσˉᑊ = 1/self.σ\n",
    "\t\t\tƻπ = 2*np.pi\n",
    "\t\t\tm = self.m\n",
    "\t\t\tdᑊᐟᒾ = np.sqrt(d)\n",
    "\t\n",
    "\t\t\tif self.method == 'orthogonal':\t# perform SORF\n",
    "\t\t\t\t#\tHere we will pad the data to ensure data dimension is in power of 2 for Hadamard matrix\n",
    "\t\t\t\tḿ = np.power(2, np.ceil(np.log2(d))) \t# dimension in power of 2 just greater than d\n",
    "\t\t\t\tΔ = int(ḿ - d)\n",
    "\t\t\t\tif Δ != 0:\n",
    "\t\t\t\t\tpad0 = np.zeros((N, Δ))\n",
    "\t\t\t\t\tX0 = np.concatenate((X, pad0), axis=1)\n",
    "\t\t\t\t#\teach loop creates ḿ out of m, we need to Figure out how many times we need to regenerate \n",
    "\t\t\t\t#\tNote the sample_num may not be equal to the actual random feature width M\n",
    "\t\t\t\t#\t\tm = the number of random features width suggested by the user\n",
    "\t\t\t\t#\t\tḿ = the number of random features generated by each hadamard matrix \n",
    "\t\t\t\t#\t\tM = the acutal number of random features we actually use since power of 2 is required by hadamard\n",
    "\t\t\t\trepeat = int(np.ceil(m/ḿ))\n",
    "\t\t\t\tW = np.empty((int(ḿ),0))\n",
    "\t\t\t\tM = int(repeat*ḿ)\n",
    "\t\t\t\tfor ɷ in range(repeat):\n",
    "\t\t\t\t\t#\tGenerate H and diagonal matrix D sampled from rademacher distribution\n",
    "\t\t\t\t\tH = 1/np.sqrt(ḿ)*hadamard(ḿ)\t\t# normalized H to be orthonormal\n",
    "\t\t\t\t\tDᑊ = self.sample_rademacher_distribution(ḿ)\n",
    "\t\t\t\t\tDᒾ = self.sample_rademacher_distribution(ḿ)\n",
    "\t\t\t\t\tDᶾ = self.sample_rademacher_distribution(ḿ)\n",
    "\t\t\t\t\t#\n",
    "\t\t\t\t\tHDᑊHDᒾHDᶾ = H.dot(Dᑊ).dot(H).dot(Dᒾ).dot(H).dot(Dᶾ)\n",
    "\t\t\t\t\tŴ = (dᑊᐟᒾ*σˉᑊ*HDᑊHDᒾHDᶾ).T\t\t\t# we did follow the paper of Wx and use XW format\n",
    "\t\t\t\t\tW = np.concatenate((W, Ŵ), axis=1)\n",
    "\t\t\t\t\t#\n",
    "\t\t\t\tθ = ƻπ*rand(1, M)\n",
    "\t\t\t\treturn [W, X0, M, θ]\n",
    "\t\t\t\t#\n",
    "\t\t\telif self.method == 'rff':\n",
    "\t\t\t\tθ = ƻπ*rand(1, m)\n",
    "\t\t\t\tW = (σˉᑊ)*np.random.randn(d, m)\t# random projection matrix W\n",
    "\t\t\t\treturn [W, X, m, θ]\n",
    "#\n",
    "\tdef get_feature_map(self, X):\n",
    "\t\t[W,Ẋ, m, θ] = self.initialize_random_features(X)\n",
    "\t\t#\n",
    "\t\tẊW = Ẋ.dot(W)\n",
    "\t\tc = np.sqrt(2.0/m)\t\n",
    "\t\treturn c*np.cos(ẊW + θ)\t\n",
    "#\n",
    "\tdef get_kernel(self, X):\n",
    "\t\tΦ = self.get_feature_map(X)\n",
    "\t\tK = Φ.dot(Φ.T)\n",
    "\t\tK = np.maximum(0,K)\t# run a relu on the kernel so no negative values\n",
    "\t\tif self.kernel == 'rbk': K = np.minimum(1,K) # make sure the kernel values doesn't go beyond 1 for gaussian\n",
    "\t\treturn K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Real                   \tApprox by SORF              \n",
      "[1.    0.858 0.668 0.312 0.586 0.327 0.651]\t[0.953 0.867 0.756 0.456 0.695 0.479 0.721]\n",
      "[0.858 1.    0.773 0.607 0.777 0.504 0.825]\t[0.867 0.973 0.835 0.714 0.841 0.659 0.862]\n",
      "[0.668 0.773 1.    0.547 0.88  0.278 0.579]\t[0.756 0.835 1.    0.67  0.93  0.424 0.68 ]\n",
      "[0.312 0.607 0.547 1.    0.721 0.493 0.493]\t[0.456 0.714 0.67  0.981 0.8   0.642 0.615]\n",
      "[0.586 0.777 0.88  0.721 1.    0.304 0.492]\t[0.695 0.841 0.93  0.8   1.    0.472 0.609]\n",
      "[0.327 0.504 0.278 0.493 0.304 1.    0.602]\t[0.479 0.659 0.424 0.642 0.472 1.    0.741]\n",
      "[0.651 0.825 0.579 0.493 0.492 0.602 1.   ]\t[0.721 0.862 0.68  0.615 0.609 0.741 0.98 ]\n",
      "                                           \t\n",
      "\n",
      "\n",
      "                    Real                   \tApprox by RFF               \n",
      "[1.    0.858 0.668 0.312 0.586 0.327 0.651]\t[0.987 0.847 0.645 0.298 0.582 0.32  0.649]\n",
      "[0.858 1.    0.773 0.607 0.777 0.504 0.825]\t[0.847 1.    0.74  0.561 0.756 0.518 0.835]\n",
      "[0.668 0.773 1.    0.547 0.88  0.278 0.579]\t[0.645 0.74  0.961 0.467 0.856 0.244 0.529]\n",
      "[0.312 0.607 0.547 1.    0.721 0.493 0.493]\t[0.298 0.561 0.467 0.935 0.626 0.513 0.465]\n",
      "[0.586 0.777 0.88  0.721 1.    0.304 0.492]\t[0.582 0.756 0.856 0.626 0.977 0.308 0.459]\n",
      "[0.327 0.504 0.278 0.493 0.304 1.    0.602]\t[0.32  0.518 0.244 0.513 0.308 1.    0.613]\n",
      "[0.651 0.825 0.579 0.493 0.492 0.602 1.   ]\t[0.649 0.835 0.529 0.465 0.459 0.613 1.   ]\n",
      "                                           \t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice that RFFperforms better on lower dimension datasets</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Mean absolute Error with SORF 0.092</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Mean absolute Error with RFF 0.026<br></h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Mean Squared Error with SORF 0.011</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Mean Squared Error with SORF 0.001</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice that SORF performs better on higher dimension datasets</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>\tMean absolute Error with SORF 0.021</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>\tMean absolute Error with RFF 0.025<br></h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>\tMean Squared Error with SORF 0.001</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>\tMean Squared Error with SORF 0.001</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tnp.set_printoptions(precision=3)\n",
    "\tnp.set_printoptions(linewidth=300)\n",
    "\tnp.set_printoptions(suppress=True)\n",
    "#\n",
    "\t#\tOn lower dimension data, it seems that RFF is good enough\n",
    "\tX = np.random.randn(7,5)\n",
    "\tσ = np.median(sklearn.metrics.pairwise.pairwise_distances(X))\n",
    "\tγ = 1.0/(2*σ*σ)\n",
    "#\n",
    "\tK = sklearn.metrics.pairwise.rbf_kernel(X, gamma=γ)\n",
    "#\n",
    "\tsorf = random_feature(sigma=σ, random_feature_method='orthogonal')\n",
    "\tKₒ = sorf.get_kernel(X)\t\t\t# kernel matrix from orthogonal\n",
    "#\n",
    "\trff = random_feature(sigma=σ, random_feature_method='rff')\n",
    "\tKᵣ = rff.get_kernel(X)\t\t\t# kernel matrix from orthogonal\n",
    "#\n",
    "#\n",
    "\tprint_two_matrices_side_by_side(K, Kₒ, title1='Real', title2='Approx by SORF', auto_print=True)\n",
    "\tprint_two_matrices_side_by_side(K, Kᵣ, title1='Real', title2='Approx by RFF', auto_print=True)\n",
    "#\n",
    "\tjupyter_print('Notice that RFFperforms better on lower dimension datasets')\n",
    "\tε = mean_absolute_error(K, Kₒ)\n",
    "\tjupyter_print('Mean absolute Error with SORF %.3f'%ε)\n",
    "\tε = mean_absolute_error(K, Kᵣ)\n",
    "\tjupyter_print('Mean absolute Error with RFF %.3f\\n'%ε)\n",
    "#\n",
    "\tε = mean_squared_error(K, Kₒ)\n",
    "\tjupyter_print('Mean Squared Error with SORF %.3f'%ε)\n",
    "\tε = mean_squared_error(K, Kᵣ)\n",
    "\tjupyter_print('Mean Squared Error with SORF %.3f'%ε)\n",
    "#\n",
    "#\n",
    "\t#\tSORF starts working better when the dimension gets larger, here we use 16 dimension\n",
    "\tX = csv_load('../dataset/letters.csv', shuffle_samples=True)\n",
    "\tX = X[0:600,:]\n",
    "#\n",
    "\tσ = np.median(sklearn.metrics.pairwise.pairwise_distances(X))\n",
    "\tγ = 1.0/(2*σ*σ)\n",
    "#\n",
    "\tK = sklearn.metrics.pairwise.rbf_kernel(X, gamma=γ)\n",
    "#\n",
    "\tsorf = random_feature(sigma=σ, random_feature_method='orthogonal')\n",
    "\tKₒ = sorf.get_kernel(X)\t\t\t# kernel matrix from orthogonal\n",
    "#\n",
    "\trff = random_feature(sigma=σ, random_feature_method='rff')\n",
    "\tKᵣ = rff.get_kernel(X)\t\t\t# kernel matrix from orthogonal\n",
    "#\n",
    "\tjupyter_print('Notice that SORF performs better on higher dimension datasets')\n",
    "\tε = mean_absolute_error(K, Kₒ)\n",
    "\tjupyter_print('\\tMean absolute Error with SORF %.3f'%ε)\n",
    "\tε = mean_absolute_error(K, Kᵣ)\n",
    "\tjupyter_print('\\tMean absolute Error with RFF %.3f\\n'%ε)\n",
    "#\n",
    "\tε = mean_squared_error(K, Kₒ)\n",
    "\tjupyter_print('\\tMean Squared Error with SORF %.3f'%ε)\n",
    "\tε = mean_squared_error(K, Kᵣ)\n",
    "\tjupyter_print('\\tMean Squared Error with SORF %.3f'%ε)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
