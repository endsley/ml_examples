{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code test the Nystrom method<br>\n",
    "Given a symmetrick kernel matrix $K \\in \\mathbb{R}^{n \\times n}$ and a submatrix L<br>\n",
    "$$K = \\begin{bmatrix} A & B^T \\\\ B & C \\end{bmatrix}, \\quad L = \\begin{bmatrix} A \\\\ B \\end{bmatrix}$$<br>\n",
    "We define the eigenvalues of matrix $A \\in \\mathbb{R}^{q \\times q}$ (where $q << n$) as <br>\n",
    "$$\\sigma(A) = \\{\\sigma_1, \\sigma_2, ..., \\sigma_q\\}$$<br>\n",
    "We define the eigenvectors of matrix $A$ as <br>\n",
    "$$V(A) = \\{v_1, v_2, ..., v_q\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nystrom method allows us to compute <br>\n",
    "1. The Entire $K$ matrix using $L$<br>\n",
    "2. The eigenvectors of $K$ using the eigenvectors of $A$<br>\n",
    "3. The inverse of $K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nystrom method explained<br>\n",
    "1. We randomly sample q samples and use that to form the top left matrix A<br>\n",
    "2. We find $\\sigma(A)$ and $V(A)$ <br>\n",
    "3. We use the r most dominant eigenvectors of A to approximate the eigenfunctions $\\phi$<br>\n",
    "\tIf we define the feature map <br>\n",
    "\t$$\\Psi_q = \\begin{bmatrix} \\psi(x_1)^T \\\\ \\psi(x_2)^T \\\\ .. \\\\ \\psi(x_q)^T \\end{bmatrix}$$<br>\n",
    "\tThen the relationship between the eigenfunction $\\phi_i$ and the eigenvector $v_i$ is<br>\n",
    "\t$$\\phi_i = \\frac{1}{\\sqrt{\\sigma_i}} \\Psi_q^T v_i$$<br>\n",
    "4. Once we approximated the eigenfunction, we can use it to approximate $K$ via the following derivation<br>\n",
    "$$K = \\Phi \\Phi^T$$<br>\n",
    "$$K = \\begin{bmatrix}  \\phi_1(x_1) & \\phi_2(x_1) & .. & \\phi_r(x_1)\\\\  \\phi_1(x_2) & \\phi_2(x_2) & .. & \\phi_r(x_2)\\\\ ... & ... & ... & ...\\\\ \\phi_1(x_n) & \\phi_2(x_n) & .. & \\phi_r(x_n) \\end{bmatrix} \\begin{bmatrix}  \\phi_1(x_1) & \\phi_2(x_1) & .. & \\phi_r(x_1)\\\\  \\phi_1(x_2) & \\phi_2(x_2) & .. & \\phi_r(x_2)\\\\ ... & ... & ... & ...\\\\ \\phi_1(x_n) & \\phi_2(x_n) & .. & \\phi_r(x_n) \\end{bmatrix}^T $$<br>\n",
    "$$K = \\begin{bmatrix} \\frac{1}{\\sqrt{\\sigma_1}} \\Psi_n \\Psi_q^T v_1  & \\frac{2}{\\sqrt{\\sigma_2}} \\Psi_n \\Psi_q^T v_2 & ... & \\frac{1}{\\sqrt{\\sigma_r}} \\Psi_n \\Psi_q^T v_r\\end{bmatrix} \\begin{bmatrix}  \\phi_1(x_1) & \\phi_2(x_1) & .. & \\phi_r(x_1)\\\\  \\phi_1(x_2) & \\phi_2(x_2) & .. & \\phi_r(x_2)\\\\ ... & ... & ... & ...\\\\ \\phi_1(x_n) & \\phi_2(x_n) & .. & \\phi_r(x_n) \\end{bmatrix}^T $$<br>\n",
    "$$K =  (\\Psi_n \\Psi_q^T V \\Sigma) (\\Psi_n \\Psi_q^T V \\Sigma)^T$$<br>\n",
    "where<br>\n",
    "$$\\Sigma = \\begin{bmatrix} \\frac{1}{\\sqrt{\\sigma_1}} & 0 & 0 & ... \\\\ 0 &  \\frac{1}{\\sqrt{\\sigma_2}} & 0 & ... \\\\ 0 &  0 & \\frac{1}{\\sqrt{\\sigma_2}} & ... \\\\ ... &  ... & ... & ... \\end{bmatrix} $$<br>\n",
    "Therefore we have<br>\n",
    "$$K =  (LV\\Sigma) (\\Sigma V^TL^T)$$<br>\n",
    "$$K =  \\Phi \\Phi^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csv_load('../dataset/wine.csv', shuffle_samples=True)\n",
    "q = 30\t\t\t\t# size of submatrix A\n",
    "n = X.shape[0]\t\t# number of total samples\n",
    "γ = get_rbf_γ(X)\t# γ used for the gaussian kerenl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Nystrom to approximate the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = X[0:q, :]\t# A will come from Xa\n",
    "L = sklearn.metrics.pairwise.rbf_kernel(X, Y=Xa, gamma=γ)\n",
    "A = L[0:q,:]\n",
    "[σs,V] = np.linalg.eig(A)\n",
    "V = V[:,0:10] # only keeping the largest eigenvectors\n",
    "Σ = np.diag(1/(np.sqrt(σs[0:10])))\n",
    "Φ = L.dot(V).dot(Σ)\n",
    "ǩ = Φ.dot(Φ.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SKlearn to approximate the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_nystroem = Nystroem(gamma=γ, random_state=1, n_components=q)\n",
    "Φ2 = feature_map_nystroem.fit_transform(X)\n",
    "K2 = Φ2.dot(Φ2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the actual kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = sklearn.metrics.pairwise.rbf_kernel(X, gamma=γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results<br>\n",
    "Notice that even though we only used 30 samples to approximate the entire 178 sample, <br>\n",
    "we still got really good approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Actual Kernel                   \tNystrom Kernel                  \n",
      "[1.     0.2303 0.0173 0.5854 0.458  0.0432 0.9369]\t[0.9996 0.2303 0.0172 0.5853 0.4582 0.0432 0.9368]\n",
      "[0.2303 1.     0.5249 0.0229 0.8947 0.7298 0.1174]\t[0.2303 0.9998 0.5248 0.0229 0.8949 0.7299 0.1175]\n",
      "[0.0173 0.5249 1.     0.0005 0.2765 0.9427 0.0059]\t[0.0172 0.5248 0.9997 0.0005 0.2765 0.9429 0.0058]\n",
      "[0.5854 0.0229 0.0005 1.     0.0737 0.0019 0.7931]\t[0.5853 0.0229 0.0005 0.9997 0.074  0.0019 0.7934]\n",
      "[0.458  0.8947 0.2765 0.0737 1.     0.4505 0.2744]\t[0.4582 0.8949 0.2765 0.074  0.9979 0.4503 0.2736]\n",
      "[0.0432 0.7298 0.9427 0.0019 0.4505 1.     0.0166]\t[0.0432 0.7299 0.9429 0.0019 0.4503 0.9998 0.0166]\n",
      "[0.9369 0.1174 0.0059 0.7931 0.2744 0.0166 1.    ]\t[0.9368 0.1175 0.0058 0.7934 0.2736 0.0166 0.9994]\n",
      "                                                  \t\n",
      "\n",
      "\n",
      "                  Actual Kernel                   \tSklearn Nystrom Kernel              \n",
      "[1.     0.2303 0.0173 0.5854 0.458  0.0432 0.9369]\t[0.9996 0.2303 0.0172 0.5853 0.4582 0.0432 0.9368]\n",
      "[0.2303 1.     0.5249 0.0229 0.8947 0.7298 0.1174]\t[0.2303 0.9998 0.5248 0.0229 0.8949 0.7299 0.1175]\n",
      "[0.0173 0.5249 1.     0.0005 0.2765 0.9427 0.0059]\t[0.0172 0.5248 0.9997 0.0005 0.2765 0.9429 0.0058]\n",
      "[0.5854 0.0229 0.0005 1.     0.0737 0.0019 0.7931]\t[0.5853 0.0229 0.0005 0.9997 0.074  0.0019 0.7934]\n",
      "[0.458  0.8947 0.2765 0.0737 1.     0.4505 0.2744]\t[0.4582 0.8949 0.2765 0.074  0.9979 0.4503 0.2736]\n",
      "[0.0432 0.7298 0.9427 0.0019 0.4505 1.     0.0166]\t[0.0432 0.7299 0.9429 0.0019 0.4503 0.9998 0.0166]\n",
      "[0.9369 0.1174 0.0059 0.7931 0.2744 0.0166 1.    ]\t[0.9368 0.1175 0.0058 0.7934 0.2736 0.0166 0.9994]\n",
      "                                                  \t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a= 100; b= 107\n",
    "print_two_matrices_side_by_side(K[a:b, a:b], ǩ[a:b, a:b], title1='Actual Kernel', title2='Nystrom Kernel')\n",
    "print_two_matrices_side_by_side(K[a:b, a:b], ǩ[a:b, a:b], title1='Actual Kernel', title2='Sklearn Nystrom Kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_error = np.sum(np.absolute(K - ǩ))/(n*n)\n",
    "avg_error2 = np.sum(np.absolute(K - K2))/(n*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>The average absolute error with Nystrom of each element is 0.000188</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>The average absolute error with Sklearn Nystrom of each element is 0.000014<br><br></h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_print('The average absolute error with Nystrom of each element is %f'% avg_error)\n",
    "jupyter_print('The average absolute error with Sklearn Nystrom of each element is %f\\n\\n'% avg_error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to use Nystrom to approximate eigenvectors of a large matrix** <br>\n",
    "The key insight is that given an approximation of the eigenfunction $\\phi_i$, the corresponding eigenvector $u_i$ of the kernel matrix K is <br>\n",
    "$$u_i = \\frac{1}{\\sqrt{\\sigma_i}} \\Psi_n \\phi_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**<br>\n",
    "1. use the eigenvectors $V$ of matrix A to approximate the eigenfunction<br>\n",
    "where $V = [v_1, v_2, ..., v_q]$, we get an expression for the eigenfunction<br>\n",
    "$$\\phi_i = \\frac{1}{\\sqrt{\\sigma_i}} \\Psi_q^T v_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, we plug the eigenvector into the previous equation to get the eigenvector<br>\n",
    "$$u_i = \\frac{1}{\\sqrt{\\sigma_i}} \\Psi_n (\\frac{1}{\\sqrt{\\sigma_i}} \\Psi_q^T v_i)$$<br>\n",
    "$$u_i = \\frac{1}{\\sigma_i} \\Psi_n \\Psi_q^T v_i$$<br>\n",
    "$$u_i = \\frac{1}{\\sigma_i} L v_i$$<br>\n",
    "$$U = L V \\begin{bmatrix} \\frac{1}{\\sigma_1} & 0 & 0 & ... \\\\ 0 & \\frac{1}{\\sigma_2} & 0 & ... \\\\  0 & 0 & \\frac{1}{\\sigma_3} & 0 & ... \\\\   \\end{bmatrix}$$<br>\n",
    "$\\Sigma$ is a diagonal matrix<br>\n",
    "$$\\bar{U} = L V \\Sigma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>We now approximate the eigenvector with only 30 samples</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_print(\"We now approximate the eigenvector with only 30 samples\")\n",
    "Σ = np.diag(1/σs[0:10]) \t# notice that Σ here is defined slightly differently\n",
    "Ū = L.dot(V).dot(Σ)\t\t\t# approximate eigenvector of the larger matrix\n",
    "[Λ, U] = np.linalg.eig(K)\t# compute the \"actual\" eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice that the approximation is not that great unless you are using a large amount of samples. </h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>For this reason, it makes sense to combine random svd with nystrom to approximate the eigenvectors</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual eigenvectors   \tApproximated Eigenvectors\n",
      "[-0.0424 -0.1298 -0.026 ]\t[-0.0646  0.3456  0.0331]\n",
      "[-0.0879  0.0552 -0.0449]\t[-0.2286 -0.0594 -0.0606]\n",
      "[-0.081   0.0644 -0.0766]\t[-0.2193 -0.084  -0.1542]\n",
      "[-0.0348 -0.1319 -0.064 ]\t[-0.0499  0.3633 -0.0501]\n",
      "[-0.0752  0.0672 -0.0929]\t[-0.2086 -0.0948 -0.2056]\n",
      "[-0.0862  0.0578 -0.0531]\t[-0.2264 -0.066  -0.0845]\n",
      "[-0.0178 -0.1113 -0.139 ]\t[-0.0226  0.3481 -0.2229]\n",
      "[-0.0912  0.0465 -0.0219]\t[-0.2313 -0.0389  0.0053]\n",
      "[-0.0904  0.049  -0.0281]\t[-0.231  -0.0446 -0.012 ]\n",
      "[-0.0879  0.0555 -0.0457]\t[-0.2291 -0.06   -0.0621]\n",
      "                         \t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jupyter_print(\"Notice that the approximation is not that great unless you are using a large amount of samples. \")\n",
    "jupyter_print(\"For this reason, it makes sense to combine random svd with nystrom to approximate the eigenvectors\")\n",
    "print_two_matrices_side_by_side(U[0:10, 0:3], Ū[0:10, 0:3], title1='Actual eigenvectors', title2='Approximated Eigenvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>Let's perform the nystrom eigenvector approximation, but with a lot more samples, q=150, instead of just 30 samples</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_print(\"Let's perform the nystrom eigenvector approximation, but with a lot more samples, q=150, instead of just 30 samples\")\n",
    "#\tInitialize all the setting\n",
    "q = 150\t\t\t\t# size of submatrix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Nystrom to approximate the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = X[0:q, :]\t# A will come from Xa\n",
    "L = sklearn.metrics.pairwise.rbf_kernel(X, Y=Xa, gamma=γ)\n",
    "A = L[0:q,:]\n",
    "[σs,V] = np.linalg.eig(A)\n",
    "V = V[:,0:10] # only keeping the largest eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Σ = np.diag(1/σs[0:10]) \t# notice that Σ here is defined slightly differently\n",
    "Ū = L.dot(V).dot(Σ)\t\t\t# approximate eigenvector of the larger matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice how much more accurate the approximation becomes!!!</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual eigenvectors   \tApproximated Eigenvectors\n",
      "[-0.0424 -0.1298 -0.026 ]\t[ 0.0476 -0.1382  0.0108]\n",
      "[-0.0879  0.0552 -0.0449]\t[ 0.0977  0.0573  0.0482]\n",
      "[-0.081   0.0644 -0.0766]\t[ 0.0904  0.0661  0.0825]\n",
      "[-0.0348 -0.1319 -0.064 ]\t[ 0.0395 -0.1422  0.0521]\n",
      "[-0.0752  0.0672 -0.0929]\t[ 0.0842  0.0687  0.1   ]\n",
      "[-0.0862  0.0578 -0.0531]\t[ 0.0959  0.0598  0.057 ]\n",
      "[-0.0178 -0.1113 -0.139 ]\t[ 0.0211 -0.1242  0.1387]\n",
      "[-0.0912  0.0465 -0.0219]\t[ 0.1012  0.0488  0.0232]\n",
      "[-0.0904  0.049  -0.0281]\t[ 0.1003  0.0513  0.0301]\n",
      "[-0.0879  0.0555 -0.0457]\t[ 0.0977  0.0576  0.0491]\n",
      "                         \t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jupyter_print(\"Notice how much more accurate the approximation becomes!!!\")\n",
    "print_two_matrices_side_by_side(U[0:10, 0:3], Ū[0:10, 0:3], title1='Actual eigenvectors', title2='Approximated Eigenvectors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
