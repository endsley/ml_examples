{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples shows how we can approximate the eigenvectors of a kernel matrix by combining random SVD and nystrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**<br>\n",
    "1. We first subsample p columns, within these p columns, we pick a smaller q columns (p >> q) and use the q columns as L for nystrom<br>\n",
    "2. We find the eigenvector from the q columns to approximate the eigenvectors for p x p matrix as V1<br>\n",
    "3. We next use V1 as a projection matrix for random svd to refine V1 into a better version V2<br>\n",
    "4. We then use V2 (better approximated) again to approximate the eigenvector of the entire kernel matrix K<br>\n",
    "<br>\n",
    "Nystrom eigenvector as Q \t-> \trandom svd refine the eigenvectors \t-> expand it to the complete Kernel matrix <br>\n",
    "nystrom expansion\t\t\t-> \tsvd refinement  \t\t\t\t\t-> nystrom expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csv_load('../dataset/wine.csv', shuffle_samples=True)\n",
    "p = 145\t\t\t\t\n",
    "q = 30\t\t\t\t\n",
    "n = X.shape[0]\t\t# number of total samples\n",
    "γ = get_rbf_γ(X)\t# γ used for the gaussian kerenl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = X[0:q, :]\t\n",
    "Xb = X[0:p, :]\n",
    "sampledK = sklearn.metrics.pairwise.rbf_kernel(X, Y=Xb, gamma=γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the true kernel from p samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = sklearn.metrics.pairwise.rbf_kernel(X, gamma=γ)\n",
    "Kp = sampledK[0:p, 0:p]\n",
    "[Λ, U] = np.linalg.eig(Kp)\t# compute the \"actual\" eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**<br>\n",
    "Use Nystrom to approximate the initial V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = sampledK[0:p, 0:q]\n",
    "A = L[0:q,:]\n",
    "[σs,V] = np.linalg.eig(A)\n",
    "V = V[:,0:10] # only keeping the largest eigenvectors\n",
    "Σ = np.diag(1/(σs[0:10]))\n",
    "V1 = L.dot(V).dot(Σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of step 1 give us a bad approximation\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>We used 30 samples to approximate eigenvector of 60 samples (Note: This approximation is not supposed to be good</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual eigenvectors       \tApproximated Eigenvectors    \n",
      "[ 0.0487  0.1401  0.0067  0.1099]\t[-0.0646  0.3456  0.0331  0.2763]\n",
      "[ 0.0995 -0.0578  0.0508  0.0022]\t[-0.2286 -0.0594 -0.0606 -0.0178]\n",
      "[ 0.0921 -0.0664  0.086   0.0473]\t[-0.2193 -0.084  -0.1542  0.0397]\n",
      "[ 0.0404  0.145   0.0478  0.0852]\t[-0.0499  0.3633 -0.0501  0.2463]\n",
      "[ 0.0857 -0.0689  0.104   0.0765]\t[-0.2086 -0.0948 -0.2056  0.0786]\n",
      "[ 0.0977 -0.0602  0.0598  0.0129]\t[-0.2264 -0.066  -0.0845 -0.0043]\n",
      "[ 0.0216  0.1288  0.1347 -0.082 ]\t[-0.0226  0.3481 -0.2229 -0.0702]\n",
      "[ 0.1031 -0.0494  0.0252 -0.0239]\t[-0.2313 -0.0389  0.0053 -0.0501]\n",
      "[ 0.1022 -0.0518  0.0322 -0.0174]\t[-0.231  -0.0446 -0.012  -0.0424]\n",
      "[ 0.0995 -0.0581  0.0517  0.0029]\t[-0.2291 -0.06   -0.0621 -0.0173]\n",
      "[ 0.0924  0.0504 -0.1053 -0.0176]\t[-0.1687  0.1576  0.294   0.0082]\n",
      "[ 0.0912 -0.0669  0.0886  0.0511]\t[-0.218  -0.0856 -0.1613  0.0448]\n",
      "[ 0.0112  0.0913  0.1458 -0.2253]\t[-0.011   0.2669 -0.2558 -0.4536]\n",
      "[ 0.104  -0.0021 -0.0656 -0.0647]\t[-0.2111  0.0587  0.2177 -0.0852]\n",
      "[ 0.0962  0.0373 -0.101  -0.0352]\t[-0.1805  0.133   0.2877 -0.0239]\n",
      "                                 \t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>The average absolute initial error with Nystrom of each element is 0.097071<br><br></h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_print('We used 30 samples to approximate eigenvector of 60 samples (Note: This approximation is not supposed to be good')\n",
    "print_two_matrices_side_by_side(U[0:15, 0:4], V1[0:15, 0:4], title1='Actual eigenvectors', title2='Approximated Eigenvectors')\n",
    "avg_error = mean_absolute_error(U[:,0:10], V1, (p*10))\n",
    "jupyter_print('The average absolute initial error with Nystrom of each element is %f\\n\\n'% avg_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**<br>\n",
    "Use qr to orthogonalize V1 as Q and shrink \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = sampledK[0:p,0:p]\n",
    "[Q,R] = np.linalg.qr(V1)\t\t# note that qr here ran on a small matrix\n",
    "M = Q.T.dot(A2)\n",
    "[Ư, Σ2, Vᵀ] = np.linalg.svd(M)\t# note that the svd here also ran on a small matrix\n",
    "V2 = Q.dot(Ư)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>We used random SVD to refine the original approximate, this should be better</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual eigenvectors       \tApproximated Eigenvectors    \n",
      "[ 0.0487  0.1401  0.0067  0.1099]\t[ 0.0487 -0.1402  0.0067  0.1099]\n",
      "[ 0.0995 -0.0578  0.0508  0.0022]\t[ 0.0995  0.0577  0.0507  0.0021]\n",
      "[ 0.0921 -0.0664  0.086   0.0473]\t[ 0.0921  0.0664  0.086   0.0474]\n",
      "[ 0.0404  0.145   0.0478  0.0852]\t[ 0.0404 -0.145   0.0478  0.0852]\n",
      "[ 0.0857 -0.0689  0.104   0.0765]\t[ 0.0857  0.0689  0.104   0.0766]\n",
      "[ 0.0977 -0.0602  0.0598  0.0129]\t[ 0.0977  0.0602  0.0597  0.0127]\n",
      "[ 0.0216  0.1288  0.1347 -0.082 ]\t[ 0.0216 -0.1288  0.1347 -0.0822]\n",
      "[ 0.1031 -0.0494  0.0252 -0.0239]\t[ 0.1031  0.0494  0.0252 -0.0239]\n",
      "[ 0.1022 -0.0518  0.0322 -0.0174]\t[ 0.1022  0.0518  0.0322 -0.0174]\n",
      "[ 0.0995 -0.0581  0.0517  0.0029]\t[ 0.0995  0.0581  0.0518  0.003 ]\n",
      "[ 0.0924  0.0504 -0.1053 -0.0176]\t[ 0.0924 -0.0504 -0.1054 -0.0177]\n",
      "[ 0.0912 -0.0669  0.0886  0.0511]\t[ 0.0912  0.0669  0.0886  0.0513]\n",
      "[ 0.0112  0.0913  0.1458 -0.2253]\t[ 0.0112 -0.0914  0.1458 -0.2254]\n",
      "[ 0.104  -0.0021 -0.0656 -0.0647]\t[ 0.1041  0.0021 -0.0656 -0.0648]\n",
      "[ 0.0962  0.0373 -0.101  -0.0352]\t[ 0.0962 -0.0373 -0.1011 -0.0352]\n",
      "                                 \t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice that the average absolute error after random svd of each element is 0.003086</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_print('We used random SVD to refine the original approximate, this should be better')\n",
    "print_two_matrices_side_by_side(U[0:15, 0:4], V2[0:15, 0:4], title1='Actual eigenvectors', title2='Approximated Eigenvectors')\n",
    "avg_error = mean_absolute_error(U[:,0:10], V2, (p*10))\n",
    "jupyter_print('Notice that the average absolute error after random svd of each element is %f'% avg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>Next, notice that the eigenvalues from random svd and the true eigenvalues are the same</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual eigenvalues 1st row / Approximated eigenvalues 2nd row\n",
      "[83.2462 36.7099 15.7864  6.021   2.0448  0.6671  0.1831  0.1565  0.0691  0.0461]\n",
      "[83.2462 36.7099 15.7864  6.021   2.0448  0.6671  0.1813  0.1562  0.0682  0.0457] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jupyter_print('Next, notice that the eigenvalues from random svd and the true eigenvalues are the same')\n",
    "print('Actual eigenvalues 1st row / Approximated eigenvalues 2nd row')\n",
    "print(Λ[0:10])\n",
    "print(Σ2[0:10], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**<br>\n",
    "Use the result from random SVD as basis of nystrom for the full kernel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Σ3 = np.diag(1/Σ2)\n",
    "Ꮭ = sampledK \n",
    "Ū = Ꮭ.dot(V2).dot(Σ3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><h3>We now obtain the eigenvector approximation and compare it to the true eigenvectors</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual eigenvectors       \tApproximated Eigenvectors    \n",
      "[-0.0424 -0.1298 -0.026  -0.0964]\t[ 0.0487 -0.1401  0.0067  0.1099]\n",
      "[-0.0879  0.0552 -0.0449 -0.0034]\t[ 0.0995  0.0578  0.0508  0.0022]\n",
      "[-0.081   0.0644 -0.0766 -0.0464]\t[ 0.0921  0.0664  0.086   0.0473]\n",
      "[-0.0348 -0.1319 -0.064  -0.0688]\t[ 0.0404 -0.145   0.0478  0.0852]\n",
      "[-0.0752  0.0672 -0.0929 -0.0745]\t[ 0.0857  0.0689  0.104   0.0765]\n",
      "[-0.0862  0.0578 -0.0531 -0.0137]\t[ 0.0977  0.0602  0.0598  0.0129]\n",
      "[-0.0178 -0.1113 -0.139   0.0927]\t[ 0.0216 -0.1288  0.1347 -0.082 ]\n",
      "[-0.0912  0.0465 -0.0219  0.0214]\t[ 0.1031  0.0494  0.0252 -0.0239]\n",
      "[-0.0904  0.049  -0.0281  0.0154]\t[ 0.1022  0.0518  0.0322 -0.0174]\n",
      "[-0.0879  0.0555 -0.0457 -0.004 ]\t[ 0.0995  0.0581  0.0517  0.0029]\n",
      "[-0.0823 -0.0522  0.0888  0.012 ]\t[ 0.0924 -0.0504 -0.1053 -0.0176]\n",
      "[-0.0802  0.0648 -0.0789 -0.0501]\t[ 0.0912  0.0669  0.0886  0.0511]\n",
      "[-0.0088 -0.0759 -0.1412  0.2184]\t[ 0.0112 -0.0913  0.1458 -0.2253]\n",
      "[-0.0926 -0.0013  0.0577  0.0584]\t[ 0.104   0.0021 -0.0656 -0.0647]\n",
      "[-0.0857 -0.0397  0.0864  0.0288]\t[ 0.0962 -0.0373 -0.101  -0.0352]\n",
      "                                 \t\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html><body><h3>Notice that the average absolute error after random svd of each element is 0.009887</h3></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[Λᴋ, Uᴋ] = np.linalg.eig(K)\t# compute the \"actual\" eigenvectors\n",
    "jupyter_print('We now obtain the eigenvector approximation and compare it to the true eigenvectors')\n",
    "print_two_matrices_side_by_side(Uᴋ[0:15, 0:4], Ū[0:15, 0:4], title1='Actual eigenvectors', title2='Approximated Eigenvectors')\n",
    "avg_error = mean_absolute_error(Uᴋ[:,0:10], Ū, (n*10))\n",
    "jupyter_print('Notice that the average absolute error after random svd of each element is %f'% avg_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
